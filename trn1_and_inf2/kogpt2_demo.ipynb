{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bfbcb86d",
   "metadata": {},
   "source": [
    "# Run Hugging Face KoGPT-2 autoregressive sampling on Inf2 & Trn1\n",
    "\n",
    "- References: https://github.com/aws-neuron/aws-neuron-samples/tree/master/torch-neuronx/transformers-neuronx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e805bd56",
   "metadata": {},
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0de11e14",
   "metadata": {},
   "source": [
    "필요 패키지\n",
    "\n",
    " - `torch-neuronx`\n",
    " - `neuronx-cc`\n",
    " - `transformers`\n",
    " - `transformers-neuronx`\n",
    "\n",
    "참조: [torch-neuronx inference setup guide](https://awsdocs-neuron.readthedocs-hosted.com/en/latest/frameworks/torch/torch-neuronx/setup/setup-inference.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69d635e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/aws-neuron/transformers-neuronx.git transformers -U"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ba693143",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 1. Compilation\n",
    "---\n",
    "\n",
    "### Load HF pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac7f84e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "from transformers_neuronx.module import save_pretrained_split\n",
    "from transformers.models.gpt2 import GPT2LMHeadModel\n",
    "from transformers_neuronx.gpt2.model import GPT2ForSampling\n",
    "\n",
    "hf_model = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2', low_cpu_mem_usage=True, torchscript=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c3a45bbb",
   "metadata": {},
   "source": [
    "### Split the model state_dict into multiple files\n",
    "\n",
    "호스트 메모리 사용량을 줄이기 위해, torch에서 기본적으로 제공하는 state_dict 메서드 대신 `transformers_neuronx` 에서 제공하는 `save_pretrained_split`를 사용할 수 있습니다. \n",
    "그리고 컴파일 및 배포 중에 메모리 사용량을 줄이기 위해 어텐션과 MLP 레이어를 FP16으로 캐스팅합니다. 이는 모델에서 각 레이어를 캐스팅하는 콜백 함수로 구현하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5efc6bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def amp_callback(model, dtype):\n",
    "    # cast attention and mlp to low precisions only; layernorms stay as f32\n",
    "    for block in model.transformer.h:\n",
    "        block.attn.to(dtype)\n",
    "        block.mlp.to(dtype)\n",
    "    model.lm_head.to(dtype)\n",
    "\n",
    "amp_callback(hf_model, torch.float16)\n",
    "save_pretrained_split(hf_model, './gpt2-split')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6ac11413",
   "metadata": {},
   "source": [
    "### Perform autoregressive sampling using tensor parallelism\n",
    "\n",
    "대규모 언어 모델을 Inf2 및 Trn1에서 작동시키기 위해 텐서 병렬화를 적용하여 모델 파라미터를 여러 뉴런코어-v2로 분할합니다. 단일 뉴런코어에 할당될 메모리 양은 `tp_degree`로 설정하며 이 값이 높아질수록 추론 속도가 더 빨라지지만, 요구하는 메모리가 증가하기 때문에\n",
    "인스턴스 사양과 모델 크기에 따라 적절한 크기를 설정해야 합니다.\n",
    "\n",
    "`transformers_neuronx` 는 현 시점에서 동적 배칭을 지원하지 않기에, 모델 컴파일 시 `batch_size` 로 지정한 배치 개수만큼 추론해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18eb464e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\n",
      "Compiler status PASS\n",
      "2023-Feb-20 08:30:57.0330 2184:4070 [1] ofi_init:1453 CCOM WARN NET/OFI aws-ofi-nccl initialization failed\n",
      "2023-Feb-20 08:30:57.0330 2184:4070 [1] init.cc:101 CCOM WARN OFI plugin initNet() failed is EFA enabled?\n",
      "..\n",
      "Compiler status PASS\n",
      "..\n",
      "Compiler status PASS\n",
      "..\n",
      "Compiler status PASS\n"
     ]
    }
   ],
   "source": [
    "# load GPT-2 to NeuronCores with 2-way tensor parallel\n",
    "# enable float16 casting\n",
    "neuron_model = GPT2ForSampling.from_pretrained('./gpt2-split', batch_size=4, tp_degree=2, amp='f16')\n",
    "neuron_model.to_neuron()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ebcab6d9",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 2. Inference\n",
    "---\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0d7067ec",
   "metadata": {},
   "source": [
    "### Load tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdd59efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
     ]
    }
   ],
   "source": [
    "from transformers import PreTrainedTokenizerFast\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(\n",
    "    \"skt/kogpt2-base-v2\",\n",
    "    bos_token='</s>',\n",
    "    eos_token='</s>',\n",
    "    unk_token='<unk>',\n",
    "    pad_token='<pad>',\n",
    "    mask_token='<mask>', \n",
    "    padding_side='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "010bd42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generate_texts(batch_prompts, tokenizer, neuron_model, sequence_length=256):\n",
    "    encodings = tokenizer.batch_encode_plus(batch_prompts, padding='longest', pad_to_max_length=True, return_tensors='pt')\n",
    "    batch_input_ids, batch_attention_masks = encodings[\"input_ids\"], encodings[\"attention_mask\"]\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        start = time.time()\n",
    "        generated_ids = neuron_model.sample(batch_input_ids, sequence_length=sequence_length)\n",
    "        elapsed = time.time() - start\n",
    "        \n",
    "    generated_texts = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "    return generated_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ac9d4d",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba4519bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 7s, sys: 80.2 ms, total: 1min 7s\n",
      "Wall time: 1.08 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['근육이 커지기 위해서는 수분섭취도 병행해야 한다.\\n특히 입술을 자주 씻어주게 되면 입술 피부가 딱딱해질 수 있기 때문에 평소 뽀얀 피부를 유지하기 위한 노력을 병행한다.\\n수분 섭취가 부족한 상태에서 물 없이 입안에 흡수된 물을 마시는 것은 피부가 건조해지는 것은 물론 자칫 얼굴로 돌아갈 수도 있기 때문에 자제해야 한다.\\n또한 충분한 수분공급을 위해서는 각질제거를 위해 바르는 에센스와 크림 등과 같이 피부에 직접 닿아도 자극이 적은 천연 화장품을 선택하는 것이 좋다.\\n특히 스킨, 로션 같은 보습제품의 사용은 피부를 매끄럽고 탄력 있게 가꾸는 데 매우 효과적이다.\\n하지만 너무 많이 바를 경우 피부에 부담이 되므로 수분공급제 등으로 케어하는 것을 소홀히 해서는 안 된다.\\n입술 피부의 건조함과 탄력을 높이는 것은 물론 보습효과가 뛰어난 크림으로 수분보충에 신경을 쓰는 것도 방법이다. 코로나 19 여파로 지난 3월 마스크 가격이 폭락하면서 방역당국이 사재기 행위를 중단하라는 국민 성원에 힘입어 소비진작에 나서면서 마스크 매출이 급증하고 있다.\\n그러나 전문가들은 마스크를 구하기 어려운 소비자들도 여전히 마스크를 구입하는 경우가 많다고 지적한다.\\n특히 마스크 가격의 급격한 하락으로 생필품을 구매하려는 이들이 많기 때문에 가격대가 저렴한 마스크를 구매해야 한다고 조언한다.\\n한국은행은 1월 마',\n",
       " '내일 날씨는 예년과 비슷하게 구름 많다가 제주도는 밤부터 장맛비가 내리기 시작하겟다.\\n내일까지 예상강수량은 제주도와 남부 내륙 5mm 안팎, 남해안, 내륙 5mm 안팎이다.\\n제주도와 남해안 최고 150mm 이상, 제주도 산지 120mm 이상 폭우가 예상된다.\\n중부지방과 경북 내륙에도 5~10mm의 비가 내릴 것으로 전망된다.\\n기상청은 이번 장맛비의 예상 강수량은 제주도 50~100mm, 전남 남해안, 지리산 부근 80mm 내외다.\\n예상 강수량은 제주도 30~60mm, 남해안과 울릉도·독도 10~30mm이고 강원 영동은 5mm 내외다.\\n강원 산지에는 최고 120mm 이상의 강수량을 기록할 것으로 보인다.\\n그밖의 지역은 10~40mm다.\\n기상청은 당분간 장맛비가 자주 내리겠다고 관측했다.\\n중국과 대만 주변 기압골의 영향으로 늦은 오후부터 장마전선의 접근이 원활하겠다.\\n장마전선의 영향으로 28일 낮부터는 기온이 차차 올라가겠다.\\n기온은 평년(7~17도)보다 4~5도 가량 높고, 낮 기온은 평년(24~30도)보다 3~5도 높을 전망이다.\\n기온은 평년과 비슷하거나 조금 높겠고, 강수량은 5~20mm로 예보됐다.\\n장마전선의 영향으로 27일 오후 이후 기온이 평년보다 3~4도 가량 높겠다.\\n당분간 낮 기온은 평년과 비슷하겠고, 기온은 평년(24',\n",
       " '수학은 그 중 으뜸에 해당한다고 주장한다.\\n즉 그 중 그 중 으뜸에는 역시 수학이 있다.\\n그러나 수학이 수학이 되지 못하는 또 다른 이유가 있으니, 바로 여기에 있다.\\n즉 수학은 사리에 맞지 않으면 잘 안 되는 것이므로 그 사리에 맞지 않은 사람이 수학은 잘하지 못한다는 것이다.\\n다시 말해 우리가 아는 수학은 사리에 맞지 않으면 잘 되지 않으며 전혀 사리에 맞지 않는 사람은 절대로 수학은 잘하지 않는다는 것이다.\\n즉 이것은 사리에 맞지 않는 사람이 반드시 사리에 맞지 않는다는 사실을 잘 알고 있는 수학자를 의미한다.\\n그렇다면 왜 사리에 맞지 않고 사리에 맞지 않는 사람이 수학에는 잘하지 못하는 것일까?\\n그렇다면 수학자의 사리는 어떻게 되는 것일까?\\n사리는 사리에 맞지 않으면 사리에 맞지 않는 것이 아니고, 사리에 맞지 않으면 사리에 맞지 않는 것이라고 한다.\\n사리에 맞는다고 사리에 맞지 않는다고 사리에 맞는 사람이라고 하는 것이 과연 타당한 것일까?\\n실제로 사리에 맞는다고 사리에 맞는 사람이 사리에 맞지 않는 사람이라고 하는 것이 과연 맞을까?\\n그러므로 사리에 맞지 않는 사람이라는 이유만으로 수학자에게 수학을 가르치는 것은 설득력을 잃게 되고 결국 수학에게는 사리에 맞지 않는 것이 될 것이다.\\n이처럼 수학자가 사리에 맞지 않는다고 사리에 맞지 않으면 수학은 잘하지도 못한다.\\n즉 사리에 맞는 일을 한 사람은 절대로 사리에 맞지 않는다고 하는 것이 올바른',\n",
       " '다윈의 진화론은 ‘근대미지’는 물론 물리적으로도 가장 강력한 상대라고 주장했다.\\n‘근대사’와 ‘근대사’라는 두 단어는 서로 상반되는 개념으로 서로 유사하지만 상대론적 논리에 따라 움직이는 것이 오히려 문제라는 것.\\n유 교수는 “수많은 사람들이 그 중 한 명처럼 진화론처럼 그 어떤 것도 진화하는 것이 아니라 ‘현대사’라는 하나의 논리로 이해하고 있는 것이 문제”라며 “특히 수학과 과학이 서로 충돌하는 분야는 물리학”이라고 강조했다.\\n이를 통해 그는 ‘근대사’나 ‘수학과 물리’가 아니라 ‘근대사’라는 것이 진정한 진화냐. 나아가 이 책을 어떻게 읽어야 할지 조언을 준다.\\n이 책은 그 첫 단계를 지나서 ‘근대사 과학’으로 정리해야 할 만큼 흥미로운 내용들이 가득 채워져 있다.\\n그는 “초보 수학자지만 우리가 가장 흔히 알고 있는 게 바로 ‘근사’라는 사실”이라며 “초보들도 알고 있는 근사학에 관심을 갖고 쉽게 찾아낼 수 있도록 다양한 책들을 통해 쉽고 재미있게 공부해보자”고 말했다.\\n2월 10일까지. 이날 서울 중구 정동 프란치스코 교육회관(4층)에서 열린 취임식에는 서옥주(경희대) 교수와 김정희(아주대) 교수 등이 참석했다.\\n이 자리에는 한병옥 숙명여대 총장, 박원순 서울시장, 강부영 서울시 교육']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "batch_prompts = [\n",
    "    \"근육이 커지기 위해서는\",\n",
    "    \"내일 날씨는\",\n",
    "    \"수학은\",\n",
    "    \"다윈의 진화론은\"\n",
    "]\n",
    "\n",
    "batch_generate_texts(batch_prompts, tokenizer, neuron_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aws_neuron_venv_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "2a95e15ad9e24cff40693df5235ea1efa507f9650d4fbf8d404bcf86897f3e33"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
