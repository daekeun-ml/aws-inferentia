{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neuron Model Prediction Demo - Computer Vision\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import cv_helper_class\n",
    "from cv_helper_class import ImgClassificationNet, VisionTransformerNet\n",
    "import matplotlib.pyplot as plt\n",
    "from common import preprocess_img\n",
    "import torch\n",
    "import torch_neuronx\n",
    "from torchvision import models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 1. Image classification (VGG, ResNet, ResNeXT, EfficientNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMGCLS_NETWORK = \"RESNET\"\n",
    "assert(IMGCLS_NETWORK in [\"VGG\", \"RESNET\", \"RESNEXT\", \"EFFICIENTNET\"])\n",
    "\n",
    "if IMGCLS_NETWORK == \"VGG\":\n",
    "    ## Choose the network size\n",
    "    VGG_SIZE = \"11\" # can be 11,11_bn,13,13_bn,16,16_bn,19,19_bn\n",
    "    assert(VGG_SIZE in ['11','11_bn','13','13_bn','16','16_bn','19','19_bn'])\n",
    "    model_name = f\"models.vgg{VGG_SIZE}\"\n",
    "elif IMGCLS_NETWORK == \"RESNET\":\n",
    "    RESNET_SIZE = 50 # can be 18,34,50,101,152   \n",
    "    assert(RESNET_SIZE in [18,34,50,101,152])\n",
    "    model_name = f\"models.resnet{RESNET_SIZE}\"\n",
    "elif IMGCLS_NETWORK == \"RESNEXT\":\n",
    "    RESNEXT_SIZE=\"50_32x4d\" # can be 50_32x4d,101_32x8d,101_64x4d\n",
    "    assert(RESNEXT_SIZE in ['50_32x4d','101_32x8d','101_64x4d'])\n",
    "    model_name=f\"models.resnext{RESNEXT_SIZE}\"\n",
    "elif IMGCLS_NETWORK == \"EFFICIENTNET\":\n",
    "    EFFICIENTNET_SIZE = 0 # can be 0,1,2,3,4,5,6,7\n",
    "    assert(EFFICIENTNET_SIZE in range(8))\n",
    "    model_name = f\"models.efficientnet_b{EFFICIENTNET_SIZE}\"\n",
    "    \n",
    "model_name_eval = eval(model_name)\n",
    "model = model_name_eval(pretrained=True) \n",
    "imgclass_net = ImgClassificationNet(model=model, model_name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Neuron model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imgclass_net.analyze()\n",
    "imgclass_net.compile()\n",
    "#imgclass_net.load(\"neuron_models.resnet50.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = preprocess_img.load_sample_imgA()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "resize_img, y_pred, y_str, y_prob = imgclass_net.get_single_predict_result(img1)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(cv2.cvtColor(resize_img, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict multiple images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img1 = preprocess_img.load_sample_imgA()\n",
    "# img2 = preprocess_img.load_sample_imgE()\n",
    "# img1 = preprocess_img.preprocess_imagenet(img1)\n",
    "# img2 = preprocess_img.preprocess_imagenet(img2)\n",
    "# img_list = [img1, img2]\n",
    "# import numpy as np\n",
    "# x = np.concatenate(img_list, axis=0)\n",
    "# outputs = imgclass_net.predict(x, data_parallel=True)\n",
    "# print(outputs.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "## 2. Vision Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import types\n",
    "from transformers import ViTFeatureExtractor, ViTForImageClassification\n",
    "\n",
    "model_name = \"vit-base-patch16-224\"\n",
    "model_type = \"vit\"\n",
    "model = ViTForImageClassification.from_pretrained(f\"google/{model_name}\")\n",
    "vit_net = VisionTransformerNet(model=model, model_name=model_name, model_type=model_type)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Neuron model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vit_net.analyze()\n",
    "vit_net.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = preprocess_img.load_sample_imgA()\n",
    "img2 = preprocess_img.load_sample_imgB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "resize_img, y_pred, y_str, y_prob = vit_net.get_single_predict_result(img1)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(cv2.cvtColor(resize_img, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict multiple images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_extractor = ViTFeatureExtractor.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "# #x = feature_extractor(img1, return_tensors=\"pt\")['pixel_values']\n",
    "# x = feature_extractor([img1, img2], return_tensors=\"pt\")['pixel_values'] # multiple images\n",
    "# outputs = vit_net.predict(x, data_parallel=True)\n",
    "# outputs.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aws_neuron_venv_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2a95e15ad9e24cff40693df5235ea1efa507f9650d4fbf8d404bcf86897f3e33"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
